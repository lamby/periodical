#!/usr/bin/env python3

import os
import re
import sys
import json
import time
import click
import jinja2
import shutil
import pickle
import logging
import requests
import tempfile
import itertools
import subprocess

from lxml import etree
from lxml.cssselect import CSSSelector
from xdg.BaseDirectory import save_cache_path

re_widont_html = re.compile(
    r'([^<>\s])\s+([^<>\s]+\s*)(</?(?:address|blockquote|br|dd|div|dt|fieldset|form|h[1-6]|li|noscript|p|td|th)[^>]*>|$)',
    re.IGNORECASE,
)
re_filename_safe = re.compile(r'\w')

DEFAULT_EXCLUDE = {
    "Christmas Crossword",
    "Christmas Quiz Questions",
    "Christmas crossword solution",
    "Crossword",
    "Crossword solution",
    "Competition",
    "Chess puzzle",
    "Coffee House",
    "Economic Disruptor Award",
    "The Best of Coffee House",
}


@click.command()
@click.argument('url', default='https://www.spectator.co.uk/magazine/')
@click.option(
    '--filename', default='', help="target filename (default: auto-generated)"
)
@click.option(
    '--keep-html',
    is_flag=True,
    default=False,
    help="Keep (and print) the HTML sources directory",
)
@click.option(
    '--include', multiple=True, help="include the specified sections"
)
@click.option(
    '--exclude', multiple=True, help="Exclude the specified sections"
)
@click.option(
    '--verbosity',
    type=int,
    default=1,
    help="Verbosity level; 0=minimal output, 1=normal output, "
    "2=verbose output, 3=very verbose output",
)
def main(*args, **kwargs):
    SpectatorToMobi(*args, **kwargs).main()


class SpectatorToMobi(object):
    def __init__(self, url, filename, keep_html, include, exclude, verbosity):
        self.epoch = time.time() - 3600
        self.session = requests.Session()

        self.base_url = url
        self.filename = filename
        self.keep_html = keep_html
        self.verbosity = verbosity

        self.exclude = DEFAULT_EXCLUDE.copy()
        for x in exclude:
            self.exclude.update(set(x.split(',')))

        for x in include:
            for y in xs.split(','):
                self.exclude.discard(y)

        # Normalise to lower-case
        self.exclude = {x.lower() for x in self.exclude}

    def main(self):
        self.context = {'articles': []}

        self.setup_logging()
        self.handle_base()

        t = tempfile.mkdtemp(prefix='spectator-to-mobi-')

        try:
            self.generate_mobi(t)
        finally:
            if self.keep_html:
                self.log.info("Keeping HTML in %s/index.html", t)
            else:
                shutil.rmtree(t, ignore_errors=True)

        return 0

    def handle_base(self):
        self.log.info("Starting conversion of %s", self.base_url)

        html = self.parse(self.base_url)

        self.context['date'] = CSSSelector('.issue-details__date')(html)[
            0
        ].text.strip()

        self.context['cover'] = CSSSelector('a.issue-details__cover-link')(
            html
        )[0].get('href')

        for x in CSSSelector('.term-item a.term-item__title-link')(html):
            self.handle_article(x.get('href'))

        # Pull to front
        for idx, x in enumerate(list(self.context['articles'])):
            if x['category'] == "Portrait of the week":
                self.context['articles'].pop(idx)
                self.context['articles'].insert(0, x)
                break

    def handle_article(self, url):
        html = self.parse(url)

        def text(x):
            try:
                elem = CSSSelector(x)(html)[0]
            except IndexError:
                return None

            return ' '.join(elem.itertext()).strip()

        author = text('.article-header .article-header__author a')
        title = text('.article-header h1')
        subtitle = text('.article-header h2')
        category = text('.article-header .article-header__category a')

        # If the title starts with the author's name, strip it out.
        title = title.replace("{}: ".format(author), "")

        # Remove some subtitles by pushing them into the title
        for x in ("Portrait of the Week", "Barometer"):
            if subtitle is not None and "{}: ".format(x) in subtitle:
                title = x
                subtitle = ""
                category = x

        if author == "The Spectator":
            author = ""

        # Fixup the leading article author
        if category == "Leading article":
            author = "The Spectator"

        # Recategorise some things
        for x, y in (
            ("Lead book review", "Books"),
            ("Leading book review", "Books"),
            ("From The Archives", "From the Archives"),
            ("Battle for Britain", "The Battle for Britain"),
            ("Notes on...", "Notes on"),
        ):
            if category == x:
                category = y

        if category.lower() in self.exclude:
            return

        # If subtitle is missing a full-stop, append one. We match for a
        # lower-case letter, to avoid whack-a-mole with various other
        # punctuation.
        if re.search(r'[a-z]$', subtitle or ''):
            subtitle = "{}.".format(subtitle)

        if category in ("Letters", "Dear Mary", "Portrait of the week"):
            title = category
            subtitle = ""

        # Rewrite title of eg. "Notes on X" to "X" if the category is "Notes of"
        if title.startswith('{} '.format(category)):
            title = title[len(category) + 1 :]

        try:
            image = CSSSelector('.featured-image img')(html)[0].get('src')
        except IndexError:
            image = None

        body = ""

        # Add metadata
        sel = CSSSelector(
            '.article-body .arts-meta, .article-body .book-meta'
        )(html)
        if sel:
            body += '<br/><br/>'
            for elem in sel:
                body += etree.tostring(elem, encoding='unicode')
                elem.getparent().remove(elem)
            body += '<br/>'

        # Parse/tidy content
        for elem in CSSSelector(
            '.article-body p, .article-body table, .article-body h2'
        )(html):
            etree.strip_tags(
                elem, 'div', 'iframe', 'script', 'v-email-newsletter'
            )
            body += etree.tostring(elem, encoding='unicode')

        for pat, repl in (
            (r'\u00a0', '&nbsp;'),
            (r'\ngoogletag.*', ''),
            (r'\u2019', '\''),
            (r'\u2018', '\''),
            (r'<p/>', ''),
            (r'<h2>', '<h5>'),
            (r'</h2>', '</h5>'),
            (r'<h3>', '<h6>'),
            (r'</h3>', '</h6>'),
            (r'<p><(?:i|em)>On the Spectator Podcast, .*</p>', ''),
            (r'<p><strong>.*Spectator Podcast.</strong></p>', ''),
            (r'<p>.*https://www.spectator.co.uk/subscription.*</p>', ''),
            (r'<!--.*MidArticle_Banner.*-->\s*<br/>', ''),
            (r'(<span class="book-meta__author">)', '<br>\\1'),
            (r'<b/>', ''),
        ):
            body = re.sub(pat, repl, body)

        if category == "Portrait of the week":
            body = re.sub(r'\s*(?:&nbsp;)*\s*[A-Z]{3}</p>', '</p>', body)

        def cb_widont(m):
            return '{}&nbsp;{}{}'.format(*m.groups())

        body = re_widont_html.sub(cb_widont, body)

        data = {
            'title': title,
            'subtitle': subtitle,
            'author': author,
            'url': url,
            'idx': len(self.context['articles']),
            'body': body,
            'image': image,
            'category': category,
        }

        self.context['articles'].append(data)

    def generate_mobi(self, tempdir):
        self.log.info("Generating .mobi in %s", tempdir)

        with open(os.path.join(tempdir, 'context.json'), 'w') as f:
            json.dump(self.context, f, indent=2)

        assert self.context[
            'articles'
        ], "No articles downloaded; please check {}".format(self.base_url)

        template_dir = os.path.join(os.path.dirname(__file__), 'templates')
        env = jinja2.Environment(loader=jinja2.FileSystemLoader(template_dir))

        self.context['tempdir'] = tempdir
        self.context['grouped'] = [
            (x, list(y))
            for x, y in itertools.groupby(
                self.context['articles'], lambda x: x['category']
            )
        ]

        self.save_url_to(
            self.context['cover'], os.path.join(tempdir, 'cover.jpg')
        )

        for x in ('index.html', 'toc.html', 'style.css'):
            val = env.get_template(x).render(**self.context)
            with open(os.path.join(tempdir, x), 'w') as f:
                f.write(val)

        # Download article images
        for x in self.context['articles']:
            if x['image'] is None:
                continue

            target = os.path.join(tempdir, '{}.jpg'.format(x['idx']))
            self.save_url_to(x['image'], target)

        # Hide kindlegen output by default
        stdout, stderr = subprocess.PIPE, subprocess.PIPE
        if self.verbosity >= 2:
            stdout, stderr = None, None

        subprocess.call(
            (
                'kindlegen/kindlegen',
                '-verbose',
                os.path.join(tempdir, 'index.html'),
            ),
            stdout=stdout,
            stderr=stderr,
        )

        if not self.filename:
            self.filename = 'The_Spectator_{}.mobi'.format(
                self.context['date'].replace(' ', '_')
            )

        self.log.info("Saving output to %s", self.filename)

        shutil.move(os.path.join(tempdir, 'index.mobi'), self.filename)

    def parse(self, *args, **kwargs):
        body = self.get(*args, **kwargs).text

        for pat, repl in (
            (r'\n', 'NEWLINE'),
            (
                r'<div class="middle-promo">.+?<div class="sub-content-promo big-bottom">.+?</div>.+?</div>.+?</div>',
                '',
            ),
            (r'NEWLINE', '\n'),
        ):
            body = re.sub(pat, repl, body)

        return etree.HTML(body)

    def get(self, url):
        filename = os.path.join(
            save_cache_path('spectator-to-mobi'),
            ''.join(x for x in url if re_filename_safe.match(x)),
        )

        if (
            os.path.exists(filename)
            and os.path.getmtime(filename) > self.epoch
        ):
            with open(filename, 'rb') as f:
                return pickle.load(f)

        response = self.session.get(url, headers={'User-agent': 'Mozilla/5.0'})
        response.raise_for_status()

        with open(filename, 'wb') as f:
            pickle.dump(response, f)

        return response

    def save_url_to(self, url, target):
        with open(target, 'wb') as f:
            for x in self.get(url).iter_content(chunk_size=128):
                f.write(x)

    def setup_logging(self):
        self.log = logging.getLogger()
        self.log.setLevel(
            {0: logging.WARNING, 1: logging.INFO, 2: logging.DEBUG}[
                self.verbosity
            ]
        )

        handler = logging.StreamHandler(sys.stderr)
        handler.setFormatter(
            logging.Formatter('%(asctime).19s %(levelname).1s %(message)s')
        )
        self.log.addHandler(handler)


if __name__ == '__main__':
    main()
